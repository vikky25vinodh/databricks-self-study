{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc76ef8-0d9f-489a-ad20-4ac5cec35fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The Medallion Architecture is a data architecture pattern that organizes data into three layers: Bronze, Silver, and Gold.\n",
    "# Each layer serves a specific purpose and helps in managing and processing data efficiently.\n",
    "\n",
    "# Bronze Layer:\n",
    "# - Raw data ingestion layer.\n",
    "# - Stores data in its raw, unprocessed form.\n",
    "# - Data is ingested from various sources like databases, APIs, and files.\n",
    "# - Schema-on-read is often used, meaning the schema is applied when the data is read.\n",
    "\n",
    "# Silver Layer:\n",
    "# - Cleansed and enriched data layer.\n",
    "# - Data is transformed, cleaned, and enriched.\n",
    "# - Schema-on-write is often used, meaning the schema is applied when the data is written.\n",
    "# - Data quality checks and transformations are applied to make the data more usable.\n",
    "\n",
    "# Gold Layer:\n",
    "# - Business-level aggregates and analytics layer.\n",
    "# - Data is aggregated, summarized, and optimized for analytics and reporting.\n",
    "# - Data is ready for consumption by business users and applications.\n",
    "# - Often used for creating dashboards, reports, and machine learning models.\n",
    "\n",
    "# Example code to demonstrate the Medallion Architecture using Spark DataFrames:\n",
    "\n",
    "# Bronze Layer: Ingest raw data\n",
    "bronze_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/dbfs/mnt/data/raw/data.csv\")\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").save(\"/path/to/bronze/table\")\n",
    "\n",
    "# Silver Layer: Cleanse and enrich data\n",
    "bronze_df = spark.read.format(\"delta\").load(\"/path/to/bronze/table\")\n",
    "silver_df = bronze_df.filter(\"some_column IS NOT NULL\").withColumn(\"new_column\", bronze_df[\"existing_column\"] * 2)\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").save(\"/path/to/silver/table\")\n",
    "\n",
    "# Gold Layer: Aggregate and summarize data\n",
    "silver_df = spark.read.format(\"delta\").load(\"/path/to/silver/table\")\n",
    "gold_df = silver_df.groupBy(\"group_column\").agg({\"value_column\": \"sum\"}).withColumnRenamed(\"sum(value_column)\", \"total_value\")\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(\"/path/to/gold/table\")\n",
    "\n",
    "# Display the Gold Layer DataFrame\n",
    "display(gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d064dda9-15f5-4e23-b1a3-ac271c374f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"A\", 10, 1),\n",
    "    (\"B\", 20, 2),\n",
    "    (\"A\", 15, None),\n",
    "    (\"C\", None, 3),\n",
    "    (\"B\", 25, 4)\n",
    "]\n",
    "columns = [\"group_column\", \"value_column\", \"existing_column\"]\n",
    "bronze_df = spark.createDataFrame(data, columns)\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").save(path_to_save_bronze_df)\n",
    "\n",
    "bronze_df=spark.read.format(\"delta\").load(path_to_save_bronze_df)\n",
    "silver_df=bronze_df.filter(col(\"existing_column\").isNotNull())\\\n",
    "    .withColumn(\"new_column\",col(\"existing_column\")*2)\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").save(path_to_save_silver_df)\n",
    "\n",
    "silver_df=spark.read.format(\"delta\").load(Path_to_save_silver_df)\n",
    "gold_df=silver_df.groupBy(\"group_column\").agg({\"value_column\":\"sum\"}).withColumnRenamed(\"sum(value_column)\",\"total_value\")\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(path_to_save_gold_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49105abe-3f74-4739-b602-f7a08d180d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Bronze Layer: Ingest raw data (example data)\n",
    "data = [\n",
    "    (\"A\", 10, 1),\n",
    "    (\"B\", 20, 2),\n",
    "    (\"A\", 15, None),\n",
    "    (\"C\", None, 3),\n",
    "    (\"B\", 25, 4)\n",
    "]\n",
    "columns = [\"group_column\", \"value_column\", \"existing_column\"]\n",
    "bronze_df = spark.createDataFrame(data, columns)\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").save(\"/Workspace/Users/vikky.vinodh.25@gmail.com/bronze_table\")\n",
    "\n",
    "# Silver Layer: Cleanse and enrich data\n",
    "bronze_df = spark.read.format(\"delta\").load(\"/tmp/bronze_table\")\n",
    "silver_df = bronze_df.filter(col(\"existing_column\").isNotNull()) \\\n",
    "    .withColumn(\"new_column\", col(\"existing_column\") * 2)\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").save(\"/Workspace/Users/vikky.vinodh.25@gmail.com/silver_table\")\n",
    "\n",
    "# Gold Layer: Aggregate and summarize data\n",
    "silver_df = spark.read.format(\"delta\").load(\"/Workspace/Users/vikky.vinodh.25@gmail.com/silver_table\")\n",
    "gold_df = silver_df.groupBy(\"group_column\") \\\n",
    "    .agg({\"value_column\": \"sum\"}) \\\n",
    "    .withColumnRenamed(\"sum(value_column)\", \"total_value\")\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(\"/Workspace/Users/vikky.vinodh.25@gmail.com/gold_table\")\n",
    "\n",
    "display(gold_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "medallion architecture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
